{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['a', 'able', 'about', 'across', 'after', 'all', 'almost', 'also',\n",
    "              'am', 'among', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because',\n",
    "              'been', 'but', 'by', 'can', 'cannot', 'could', 'dear',\n",
    "              'did', 'do', 'does', 'either', 'else', 'ever', 'every', 'for',\n",
    "              'from', 'get', 'got', 'had', 'has', 'have', 'he', 'her', 'hers',\n",
    "              'him', 'his', 'how', 'however', 'i', 'if', 'in', 'into', 'is',\n",
    "              'it', 'its', 'just', 'least', 'let', 'like', 'likely', 'may',\n",
    "              'me', 'might', 'most', 'must', 'my', 'neither', 'no', 'nor',\n",
    "              'not', 'of', 'off', 'often', 'on', 'only', 'or', 'other', 'our',\n",
    "              'own', 'rather', 'said', 'say', 'says', 'she', 'should', 'since',\n",
    "              'so', 'some', 'than', 'that', 'the', 'their', 'them', 'then',\n",
    "              'there', 'these', 'they', 'this', 'tis', 'to', 'too', 'twas', 'us',\n",
    "              've', 'wants', 'was', 'we', 'were', 'what', 'when', 'where', 'which',\n",
    "              'while', 'who', 'whom', 'why', 'will', 'with', 'would', 'yet',\n",
    "              'you', 'your']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(line):\n",
    "    line = line.split('\\n')\n",
    "    line = [re.sub('[^A-Za-z]', ' ', i) for i in line]\n",
    "    line = [i.split() for i in line]\n",
    "    line = [item for sublist in line for item in sublist]\n",
    "    line = [word.strip().lower() for word in line if word not in stop_words if len(word) >= 3]\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Positive Sentences: 5331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[57] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pData = sc.textFile(\"C:\\Users\\KARAN\\Documents\\BDA\\pos_data.txt\")\n",
    "ptData = pData.map(lambda text : LabeledPoint(1, HashingTF().transform(parse(text))))\n",
    "print \"No. of Positive Sentences: \" + str(ptData.count())\n",
    "ptData.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Negative Sentences: 5331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[78] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nData = sc.textFile(\"C:\\Users\\KARAN\\Documents\\BDA\\data_neg.txt\")\n",
    "ntData = nData.map(lambda text : LabeledPoint(0, HashingTF().transform(parse(text))))\n",
    "print \"No. of Negative Sentences: \" + str(ntData.count())\n",
    "ntData.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptrain, ptest = ptData.randomSplit([0.7, 0.3])\n",
    "ntrain, ntest = ntData.randomSplit([0.7, 0.3])\n",
    "trainh = ptrain.union(ntrain)\n",
    "testh = ptest.union(ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = NaiveBayes.train(trainh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier correctly predicted category 77.1735791091 percent of the time\n"
     ]
    }
   ],
   "source": [
    "prediction_and_labels = testh.map(lambda point: (model.predict(point.features), point.label))\n",
    "correct = prediction_and_labels.filter(lambda (predicted, actual): predicted == actual)\n",
    "accuracy = correct.count() / float(testh.count())\n",
    "print \"Classifier correctly predicted category \" + str(accuracy * 100) + \" percent of the time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
