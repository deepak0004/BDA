{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(line):\n",
    "    line = re.sub('[:][)]', ' happy ', line)\n",
    "    line = re.sub('[:][-][)]', ' happy ', line)\n",
    "    line = re.sub('[:][(]', ' sad ', line)\n",
    "    line = re.sub('[:][-][(]', ' sad ', line)\n",
    "    line = re.sub('[^A-Za-z]', ' ', line)\n",
    "    line = line.split()\n",
    "    line = [word.strip().lower() for word in line if word not in stop_words if len(word) >= 3]\n",
    "    line = [PorterStemmer().stem(word) for word in line]\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Positive Sentences: 24003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pData = sc.textFile(\"C:\\Users\\KARAN\\Documents\\BDA\\data_pos.txt\")\n",
    "ptData = pData.map(lambda text : LabeledPoint(1, HashingTF().transform(parse(text))))\n",
    "print \"No. of Positive Sentences: \" + str(ptData.count())\n",
    "ptData.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Negative Sentences: 16279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[19] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nData = sc.textFile(\"C:\\Users\\KARAN\\Documents\\BDA\\data_neg.txt\")\n",
    "ntData = nData.map(lambda text : LabeledPoint(0, HashingTF().transform(parse(text))))\n",
    "print \"No. of Negative Sentences: \" + str(ntData.count())\n",
    "ntData.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Training Data: 24162\n",
      "No. of Testing Data: 16120\n"
     ]
    }
   ],
   "source": [
    "ptrain, ptest = ptData.randomSplit([0.6, 0.4])\n",
    "ntrain, ntest = ntData.randomSplit([0.6, 0.4])\n",
    "trainh = ptrain.union(ntrain)\n",
    "testh = ptest.union(ntest)\n",
    "print \"No. of Training Data: \" + str(trainh.count())\n",
    "print \"No. of Testing Data: \" + str(testh.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionWithLBFGS.train(trainh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier correctly predicted category 82.0037220844 percent of the time\n"
     ]
    }
   ],
   "source": [
    "prediction_and_labels = testh.map(lambda point: (model.predict(point.features), point.label))\n",
    "correct = prediction_and_labels.filter(lambda (predicted, actual): predicted == actual)\n",
    "accuracy = correct.count() / float(testh.count())\n",
    "print \"Classifier correctly predicted category \" + str(accuracy * 100) + \" percent of the time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData = sc.textFile(\"C:\\Users\\KARAN\\Documents\\BDA\\data_all.txt\")\n",
    "allh = allData.map(lambda text : LabeledPoint(1, HashingTF().transform(parse(text))))\n",
    "print \"Total number of Sentences: \" + str(allh.count())\n",
    "allh.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Testing Data: 16120\n"
     ]
    }
   ],
   "source": [
    "prediction_and_labels = allh.map(lambda point: (model.predict(point.features), point.label))\n",
    "\n",
    "def toCSVLine(data):\n",
    "    return data[0]\n",
    "\n",
    "lines = prediction_and_labels.map(toCSVLine)\n",
    "lines.saveAsTextFile('C:\\Users\\KARAN\\Documents\\BDA\\out_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
